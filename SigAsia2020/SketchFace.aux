\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{SutherlandSketchPad64,Zeleznik-Sketch96,Igarashi-teddy99,Chen_sketchingreality08,Chen09sketch2photo}
\citation{pix2pix,pix2pixHD,CycleGANs,DualGAN,DiscoGANs,DualGANs,BicycleGANs}
\citation{pix2pix,pix2pixHD,Lines2Face}
\HyPL@Entry{0<</S/D>>}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces This is a teaser\relax }}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:teaser}{{1}{1}{This is a teaser\relax }{figure.caption.1}{}}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{pix2pix}
\citation{outdoor_scene}
\citation{BicycleGAN}
\citation{CycleGAN}
\citation{DualGAN}
\citation{DiscoGAN}
\citation{StarGAN}
\citation{pix2pixHD}
\citation{Sketch2Photo}
\citation{PhotoSketcher}
\citation{SketchyGAN}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Image-to-Image Translation}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sketch-based Image generation}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}pooling}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Face Generation and Editing}{2}{subsection.2.4}\protected@file@percent }
\citation{pix2pixHD}
\citation{HED}
\citation{CSAGAM}
\citation{pix2pixHD}
\citation{CelebAMask-HQ}
\citation{FaceShop}
\citation{AutoTrace}
\citation{DeepSurgery}
\@writefile{toc}{\contentsline {section}{\numberline {3}Deep Network for Sketch-Photo Translation}{3}{section.3}\protected@file@percent }
\newlabel{sec:network}{{3}{3}{Deep Network for Sketch-Photo Translation}{section.3}{}}
\newlabel{subsec:algorithm_data}{{3.0.1}{3}{Face Sketches and Stroke Deformation}{subsubsection.3.0.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.1}Face Sketches and Stroke Deformation}{3}{subsubsection.3.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Stroke Deformation}{3}{section*.7}\protected@file@percent }
\newlabel{subsec:algorithm_sap}{{3.0.2}{3}{Spatial Attention Pooling}{subsubsection.3.0.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.2}Spatial Attention Pooling}{3}{subsubsection.3.0.2}\protected@file@percent }
\citation{pix2pixHD}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The architecture of our model.\relax }}{4}{figure.caption.6}\protected@file@percent }
\newlabel{fig:architecture}{{2}{4}{The architecture of our model.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison between a sketch generated from edge detection and from semantic boundary.\relax }}{4}{figure.caption.8}\protected@file@percent }
\newlabel{fig:sketch_data}{{3}{4}{Comparison between a sketch generated from edge detection and from semantic boundary.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sap\relax }}{4}{figure.caption.9}\protected@file@percent }
\newlabel{fig:sap}{{4}{4}{Sap\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Traning Schedule}{4}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:ep}{{3.1}{4}{Traning Schedule}{subsection.3.1}{}}
\newlabel{subsec:algorithm_loss}{{3.1.1}{4}{Losses}{subsubsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Losses}{4}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{eqn:loss_GFM}{{3}{4}{Losses}{equation.3.3}{}}
\citation{}
\citation{tsne}
\citation{tsne}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sketch interface. \leavevmode {\color  {blue}Full interface with editing tools.}\relax }}{5}{figure.caption.10}\protected@file@percent }
\newlabel{fig:interface}{{5}{5}{Sketch interface. \td {Full interface with editing tools.}\relax }{figure.caption.10}{}}
\newlabel{eqn:new_minmax_game}{{4}{5}{Losses}{equation.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{5}{section.4}\protected@file@percent }
\newlabel{sec:experiments}{{4}{5}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Sketch Interface}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Face Generation from Contours}{5}{subsection.4.2}\protected@file@percent }
\newlabel{sec:contourExp}{{4.2}{5}{Face Generation from Contours}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Contour Dataset}{5}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Photo Generation from Contours}{5}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Face Editing with Strokes}{5}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Face generation with different models. From left to right: (a) hand-drawn sketches as input. (b) Results generated by pix2pixHD that is retrained using our contour-photo dataset. (c) Results generated by pix2pixHD that is retrained using our contour-photo dataset with geometric transformation as data augmentation. (d) Results generated by removing instance normalization at the shallow convolution layers (five layers in the global generator). (e) Results from our model (pix2pixHd architecture by replacing instance normalization with the proposed SLRN. ) More results can be found here: \leavevmode {\color  {red}(Provide a link for all results.)} \relax }}{5}{figure.caption.13}\protected@file@percent }
\newlabel{fig:cmp-contour-generation}{{6}{5}{Face generation with different models. From left to right: (a) hand-drawn sketches as input. (b) Results generated by pix2pixHD that is retrained using our contour-photo dataset. (c) Results generated by pix2pixHD that is retrained using our contour-photo dataset with geometric transformation as data augmentation. (d) Results generated by removing instance normalization at the shallow convolution layers (five layers in the global generator). (e) Results from our model (pix2pixHd architecture by replacing instance normalization with the proposed SLRN. ) More results can be found here: \cxj {Provide a link for all results.} \relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Local face editing with different models. \leavevmode {\color  {blue}The proposed SLRN captures the shape details in the drawn sketches and successfully avoid edge-aligned artifacts caused by distortion in hand-drawn sketches.} More results can be found here: \leavevmode {\color  {red}(Provide a link for all results.)} \relax }}{5}{figure.caption.15}\protected@file@percent }
\newlabel{fig:cmp-contour-editing}{{7}{5}{Local face editing with different models. \td {The proposed SLRN captures the shape details in the drawn sketches and successfully avoid edge-aligned artifacts caused by distortion in hand-drawn sketches.} More results can be found here: \cxj {Provide a link for all results.} \relax }{figure.caption.15}{}}
\bibstyle{ACM-Reference-Format}
\bibdata{sketch}
\bibcite{Sketch2Photo}{{1}{2009}{{Chen et~al\mbox  {.}}}{{Chen, Cheng, Tan, Shamir, and Hu}}}
\bibcite{PhotoSketcher}{{2}{2011}{{{Eitz} et~al\mbox  {.}}}{{{Eitz}, {Richter}, {Hildebrand}, {Boubekeur}, and {Alexa}}}}
\bibcite{pix2pix}{{3}{2017}{{Isola et~al\mbox  {.}}}{{Isola, Zhu, Zhou, and Efros}}}
\bibcite{outdoor_scene}{{4}{2016}{{Karacan et~al\mbox  {.}}}{{Karacan, Akata, Erdem, and Erdem}}}
\bibcite{DiscoGANs}{{5}{2017}{{Kim et~al\mbox  {.}}}{{Kim, Cha, Kim, Lee, and Kim}}}
\bibcite{Lines2Face}{{6}{2019}{{Li et~al\mbox  {.}}}{{Li, Chen, Wu, and Zha}}}
\bibcite{pix2pixHD}{{7}{2018}{{Wang et~al\mbox  {.}}}{{Wang, Liu, Zhu, Tao, Kautz, and Catanzaro}}}
\bibcite{HED}{{8}{2015}{{Xie and Tu}}{{Xie and Tu}}}
\bibcite{DualGANs}{{9}{2017}{{Yi et~al\mbox  {.}}}{{Yi, Zhang, Tan, and Gong}}}
\bibcite{CycleGANs}{{10}{2017a}{{Zhu et~al\mbox  {.}}}{{Zhu, Park, Isola, and Efros}}}
\bibcite{BicycleGANs}{{11}{2017b}{{Zhu et~al\mbox  {.}}}{{Zhu, Zhang, Pathak, Darrell, Efros, Wang, and Shechtman}}}
\bibdata{sketchRef}
\bibcite{Sketch2Photo}{{1}{2009}{{Chen et~al\mbox  {.}}}{{Chen, Cheng, Tan, Shamir, and Hu}}}
\bibcite{PhotoSketcher}{{2}{2011}{{{Eitz} et~al\mbox  {.}}}{{{Eitz}, {Richter}, {Hildebrand}, {Boubekeur}, and {Alexa}}}}
\bibcite{pix2pix}{{3}{2017}{{Isola et~al\mbox  {.}}}{{Isola, Zhu, Zhou, and Efros}}}
\bibcite{outdoor_scene}{{4}{2016}{{Karacan et~al\mbox  {.}}}{{Karacan, Akata, Erdem, and Erdem}}}
\bibcite{DiscoGANs}{{5}{2017}{{Kim et~al\mbox  {.}}}{{Kim, Cha, Kim, Lee, and Kim}}}
\bibcite{Lines2Face}{{6}{2019}{{Li et~al\mbox  {.}}}{{Li, Chen, Wu, and Zha}}}
\bibcite{pix2pixHD}{{7}{2018}{{Wang et~al\mbox  {.}}}{{Wang, Liu, Zhu, Tao, Kautz, and Catanzaro}}}
\bibcite{HED}{{8}{2015}{{Xie and Tu}}{{Xie and Tu}}}
\bibcite{DualGANs}{{9}{2017}{{Yi et~al\mbox  {.}}}{{Yi, Zhang, Tan, and Gong}}}
\bibcite{CycleGANs}{{10}{2017a}{{Zhu et~al\mbox  {.}}}{{Zhu, Park, Isola, and Efros}}}
\bibcite{BicycleGANs}{{11}{2017b}{{Zhu et~al\mbox  {.}}}{{Zhu, Zhang, Pathak, Darrell, Efros, Wang, and Shechtman}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.185pt}
\newlabel{tocindent2}{10.35pt}
\newlabel{tocindent3}{18.198pt}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Visualization of extracted features under local editing. We extract the features at different convolution layers at the left eye position (a) from three groups of sketches (b) with different types of local editing. The extracted high-dimensional features using different models including pix2pixHD-DA, pix2pixHD-wo-IN, and our SLRN) are mapped into 2D space using TSNE\nonbreakingspace \citep  {tsne} in (c). \leavevmode {\color  {red}(ChengZhiHua: provide a link for all results.)} \relax }}{6}{figure.caption.16}\protected@file@percent }
\newlabel{fig:vis-feature-slpn}{{8}{6}{Visualization of extracted features under local editing. We extract the features at different convolution layers at the left eye position (a) from three groups of sketches (b) with different types of local editing. The extracted high-dimensional features using different models including pix2pixHD-DA, pix2pixHD-wo-IN, and our SLRN) are mapped into 2D space using TSNE~\cite {tsne} in (c). \cxj {ChengZhiHua: provide a link for all results.} \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison with Image Translation networks}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Comparison with Image Editing}{6}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Limitations and future work}{6}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{6}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{6}{section*.20}\protected@file@percent }
\newlabel{TotPages}{{6}{6}{}{page.6}{}}
