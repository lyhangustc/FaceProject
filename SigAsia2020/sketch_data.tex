% !TeX root = SketchFace.tex

\subsubsection{Face Sketches and Data Augmentation}
Paired face sketch-photo dataset is required for supervised sketch-to-face generation methods.
Since there exits no large-scale face sketch datasets, the training face sketches used by existing methods are generated from face image dataset, e.g. CelebA-HQ face dataset, using edge detection algorithm such as HED~\cite{HED}.
However, the sketches generated by edge detection algorithm are sometimes incomplete or \td{other problems}. Although CSAGAN~\cite{CSAGAM} applied self-attention mechanism to alleviate the incompleteness problem, the others remains. Therefore we use another method to generate clearer and complete sketches from face images.
The CelebAMask-HQ dataset~\cite{CelebAMask-HQ} provides a face semantic map for each face image in CelebA-HQ dataset. We basically use the boundary map of the semantic map as the sketch of the corresponding face image. Figure~\ref{fig:sketch_data} shows an example of comparison between a sketch generated by edge detector and from semantic boundary.

A shortcut of sketches generated from semantic boundary (and those generated by edge detector) is the lines of sketches are perfectly aligned to the edges of the corresponding face images. In order to break the edge-alignment and mimic the hand-drawn sketches, we apply a deform to the lines. Specifically, we vectorize the lines of each sketches using AutoTrace algorithm~\cite{AutoTrace}, and add an offset randomly selected from $[-d, d]^2$ to the control points and end points of the vectorized lines, where $d$ is the maximum offset and we set $d=11$ in our experiments.


\begin{figure}
	\centering
	\vspace{1.0cm}
	\caption{Comparison between a sketch generated from edge detection and from semantic boundary.}
	\label{fig:sketch_data}
\end{figure}