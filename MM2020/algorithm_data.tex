% !TeX root = SketchFace.tex


Paired face sketch-photo dataset is required for supervised sketch-to-face translation methods.
Since there exits no large-scale paired sketch dataset, the training sketches used by existing methods~\cite{pix2pix, Lines2Face} are generated from face image dataset, e.g. CelebA-HQ face dataset, using edge detection algorithm such as HED~\cite{HED}.
%
However, the level of details in edge maps rely heavily on the value of a threshold of edge detection algorithm. An edge map with a large threshold contains too many redundant edges while an edge map with a small threshold fails to preserve the entire global facial structure~\cite{Lines2Face}.

Pix2pixHD~\cite{pix2pixHD} introduces another method to generate sketches from face images. Given a face image, the face landmarks are detected using an off-shelf landmark detection model. A new kind of sketch, denoted as \textit{face contour}, is obtained by connect specific landmarks. However, since the pre-defined face landmarks mainly depict the facial area,  a sketch-to-face model trained by face contours fails to generalize to hand-drawn sketches with hair, beard, or ornaments . 

Based on the discussion above, we utilize a new kind of generated sketches with the assist of semantic maps.
The CelebAMask-HQ dataset~\cite{CelebAMask-HQ} provides a face semantic map for each face image in CelebA-HQ dataset. We basically use the boundary map of the semantic map as the sketch of the corresponding face image. Figure~\ref{fig:sketch_data} shows an example of comparison between an edge map (b), a face contour (c) and a sketch generated from semantic boundary (d) from the same real image (a).
%


\paragraph{Stroke Deformation}
A shortcut of sketches generated from semantic boundary (and those generated by edge detector) is that lines of sketches are perfectly aligned to edges of the corresponding face images. In order to break the edge-alignment between sketches and the corresponding real images and mimic the strokes of hand-drawn sketches, we apply a deformation to the lines, using a method similar to that in FaceShop~\cite{FaceShop}. Specifically, we vectorize lines of each sketches using AutoTrace algorithm~\cite{AutoTrace}. Then offsets randomly selected from $[-d, d]^2$ are added to the control points and end points of the vectorized lines, where $d$ is the maximum offset and we set $d=11$ in our experiments unless specifically mentioned.
%
We use the semantic boundary map as edge-aligned sketch, denoted as $S$, and semantic boundary map with random deformation as deformed sketch, $S'$.

