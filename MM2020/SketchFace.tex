
\documentclass[sigconf,anonymous,review]{acmart}
\acmSubmissionID{1570}

\usepackage{booktabs} % For formal tables
\usepackage{color}
 % to balance the end of two columns
\usepackage{balance}
\usepackage{bm}
% TOG prefers author-name bib system with square brackets
%\citestyle{acmauthoryear}
%\setcitestyle{nosort,square} % nosort to allow for manual chronological ordering



\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}

% Metadata Information
%\acmJournal{TOG}
%\acmVolume{38}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2019}
%\acmMonth{7}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\acmDOI{0000001.0000001_2}

% Paper history
%\received{February 2007}
%\received{March 2009}
%\received[final version]{June 2009}
%\received[accepted]{July 2009}

\setcopyright{acmcopyright}
\copyrightyear{2020}
\acmYear{2020}
\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[MM '20]{Proceedings of the 27th ACM International Conference on Multimedia}{October 21--25, 2020}{Seattle, US}
\acmBooktitle{Proceedings of the 27th ACM International Conference on Multimedia (MM '20), October 21--25, 2020, Seattle, US}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/20/06}

\newcommand{\cxj}[1]{\textcolor{red}{(#1)}}
\newcommand{\td}[1]{\textcolor{blue}{#1}}
\newcommand{\rmv}[1]{\textcolor{green}{#1}}
\newcommand{\real}{{\mathbb{R}}}
\newcommand{\synS}{\mathcal{S}_{syn}}
\newcommand{\dfmS}{\mathcal{S}_{dfm}}
\newcommand{\hdS}{\mathcal{S}}
\newcommand{\dlt}[1]{}


% Document starts
\begin{document}
% Title portion
%\title{FaceSketching: Interactive Realistic Face Image Creation from Free-hand Sketches }
\title{DeepFacePencil: Creating Face Images from Freehand Sketches}

\begin{abstract}
In this paper, we explore the task of generating photo-realistic face images from hand-drawn sketches. 
%
Existing image-to-image translation methods require a large-scale dataset of paired sketches and images for supervision.
They typically utilize synthesized edge maps of face images as training data. 
However, these synthesized edge maps strictly align with the edges of the corresponding face images, which limit their generalization ability to real hand-drawn sketches with vast stroke diversity. 
To address this problem, we propose DeepFacePencil, an effective tool that is able to generate photo-realistic face images from hand-drawn sketches, based on a novel dual generator image translation network during training. 
%
A novel spatial attention pooling (SAP) is designed to adaptively handle stroke distortions which are spatially varying to support various stroke styles and different level of details.
We conduct extensive experiments and the results demonstrate the superiority of our model over existing methods on both image quality and model generalization to handdrawn sketches.
\end{abstract}

% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10010147.10010257.10010293.10010294</concept_id>
	<concept_desc>Computing methodologies~Neural networks</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Neural networks}

%\keywords{spatial attention; conditional generative adversarial nets; face; sketch; realistic images}

%
% End generated code
%


\keywords{Image synthesis, spatial attention, sketch-based interface,
face editing, conditional generative adversarial networks}

\dlt{
\begin{teaserfigure}
	\includegraphics[width=\textwidth]{figs/teaser.png}
	\caption{This is a teaser}
	\label{fig:teaser}
\end{teaserfigure}
}

\maketitle

\input{intro}
\input{relatedwork}
\input{algorithm}
\input{experiment}


\section{Conclusion}
In this paper, we present DeepFacePencil, a novel deep neural network which allows common users to create photorealistic by freehand sketching.
%
The robustness of our sketch-based face generator comes from the proposed dual generators and the spatial attention pooling module. 
%
The proposed spatial attention pooling module adaptively adjusts the spatially varying balance between the image realism and the conformance between the input sketch and the synthesized image. 
%
By adding the SAP module to our dual-generator network and training the two generators simultaneously to enforce the main generator to effectively capture face structure and facial feature shapes from coarsely drawn sketches. 
Extensive experiments demonstrate that our DeepFacePencil successfully produce high quality face images from freehand sketches drawn by users in diverse drawing skills.
%



% Bibliography
\bibliographystyle{ACM-Reference-Format}
\balance 
\bibliography{sketch}
%\bibliography{sketchRef}



\end{document}
