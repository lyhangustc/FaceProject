% !TeX root = ../main.tex

\chapter{特征可视化}

\section{t-SNE原理}

高维数据的可视化在许多不同的领域都一直是一个非常重要的问题，近几十年来提出了许多可视化的方法，而数据降维是其中非常重要的一种。降维，顾名思义就是将高维空间中的数据降低维度。通常变成二维或三维的形式，方便以散点图的形式展现，帮助人们更好地分析数据。降维后的数据能否保留原始数据之间的关系以及降维后的可视化效果成为衡量一种降维方法优劣的两大标准。

降维方法一般分为线性降维和非线性降维，线性降维包括主成分分析(PCA)、多维尺度变换(MDS)等，非线性降维包括等度量映射(Isomap)、局部线性嵌入(LLE)和随机近邻嵌入(SNE)等。线性降维通常会将高维空间中不同的数据点在低维表示中远远分开，对于高维空间中相同或相近的数据点其表示能力则存在不足。非线性降维可以很好地弥补这一缺点。t-SNE便是一种非线性降维方法，它在SNE的基础上做了几点改进。

\subsection{SNE}

随机近邻嵌入首先将高维空间数据点之间的欧氏距离转换为表示相似性的条件概率分布。考虑高维空间中两个数据点$\vx_i$和$\vx_j$，以$p_{j|i}$表示$\vx_i$选择$\vx_j$作为其近邻点的条件概率。$\vx_j$与$\vx_i$的欧氏距离越小，则$p_{j|i}$越大。如果用高斯分布描述这种条件概率，则其数学表达形式为：
\begin{equation}
	p_{j|i} = \frac{\exp(-\lVert \vx_i-\vx_j\rVert^2 /2\sigma_{i}^{2})}{\sum_{k\ne i}{\exp(-\lVert \vx_i-\vx_k \rVert^2 /2\sigma_{i}^{2})}}
\end{equation}
\noindent
其中$\sigma_i$表示以$\vx_i$为中心的高斯分布的方差。设$\vx_i$和$\vx_j$映射到低维空间的点分别为$\vy_i$和$\vy_j$，同样地，用条件概率$q_{j|i}$表示低维空间点的相似性，其数学表达形式为:
\begin{equation}
	q_{j|i} = \frac{\exp(-\lVert \vy_i-\vy_j\rVert^2 )}{\sum_{k\ne i}{\exp(-\lVert \vy_i-\vy_k \rVert^2 )}}
\end{equation}

为了使$\vy_i$和$\vy_j$可以真实地反映$\vx_i$和$\vx_j$之间的关系，理论上应该让条件概率$p_{j|i}$与$q_{j|i}$完全相等。用$\symup{P}_i$表示给定$\vx_i$与其余所有点之间的条件概率分布，$\symup{Q}_i$表示$\vy_i$与其余各点之间的条件概率分布，应该使$\symup{Q}_i$与$\symup{P}_i$完全相等，所以用$\symup{P}_i$与$\symup{Q}_i$的KL距离作为代价函数：
\begin{equation}
	C=\sum_{i}{KL(P_i \lVert Q_i)}=\sum_{i}{\sum_{j}{p_{j|i}\log\frac{p_{j|i}}{q_{j|i}}}}
\end{equation}

由于KL散度是非对称的，因此在低维空间中，不同类型的误差在两两距离上的权重并不相等。特别地，如果高维空间中相距很近的点被映射到低维空间后距离很远，将得到很大的代价；而如果在高维空间中相距很远的点被映射成距离很近的点，得到的代价不会很大。这说明，SNE的一大缺陷就是更关注局部结构而忽视了全局。

%\noindent
代价函数C对$\vy_i$求梯度后有一个简单的形式：
\begin{equation}
	\frac{\delta C}{\delta \vy_i}=2\sum_{j}{(p_{j|i}-q_{j|i}+p_{i|j}-q_{i|j})(\vy_i-\vy_j)}
\end{equation}

%\noindent
常常利用带动量的随机梯度下降算法优化低维空间点的分布：
\begin{equation}
	\mathcal{Y}^{(t)}=\mathcal{Y}^{(t-1)}+\eta\frac{\delta C}{\delta \mathcal{Y}}+\alpha(t)(\mathcal{Y}^{(t-1)}-\mathcal{Y}^{(t-2)})
\end{equation}

\subsection{t-SNE}

t-SNE在SNE的基础上做了两点改进：

%\subsubsection{将原始的SNE转变成对称SNE}
\noindent
1.将原始的SNE转变成对称SNE

在原来的SNE中，$p_{j|i}\ne p_{i|j}$，且$q_{j|i}\ne q_{i|j}$，是非对称的，则在高维空间和低维空间中分别构造出对称的联合概率分布P和Q，使得对任意的$i$，$j$，均有$p_{ij}=p_{ji}$，$q_{ij}=q_{ji}$。构造的$p_{ij}$有如下形式：
\begin{equation}
	p_{ij}=\frac{p_{j|i}+p_{i|j}}{2n}
\end{equation}

其中，$n$为数据点的数量，这种定义既满足了对称性，也保证了对于离群点$\vx_i$代价惩罚不致太小。代价函数重写为：
\begin{equation}
	C=KL(P \lVert Q)=\sum_{i}{\sum_{j}{p_{ij}\log\frac{p_{ij}}{q_{ij}}}}
\end{equation}
\noindent
梯度函数变为：
\begin{equation}
	\frac{\delta C}{\delta \vy_i}=4\sum_{j}{(p_{ij}-q_{ij})(\vy_i-\vy_j)}
\end{equation}
\noindent
可见比之前的形式更为简洁，计算效率更高。

~\\
\noindent
2.将低维空间中的数据分布表示为t分布

t分布是长尾分布，相比于正态分布可以更好地将高维数据映射到低维空间。举例来说，在高维空间中距离相近的点，为了满足$p_{ij}=q_{ij}$，映射到低维空间后距离会更近；而在高维空间中距离较远的点，映射到低维空间后距离会拉大。这使得同类别的点或者说相似的点在低维空间分布得更为紧密，而不同类别的点或者说相似性较低的点分布得更为稀疏，从而使可视化的效果更好。

用t分布重新定义低维空间的联合概率分布：
\begin{equation}
	q_{ij} = \frac{(1+\lVert \vy_i-\vy_j\rVert^2)^{-1}}{\sum_{k\ne l}{(1+\lVert \vy_k-\vy_l \rVert^2)^{-1}}}
\end{equation}

代价函数与之前相同，梯度的形式变为：
\begin{equation}
	\frac{\delta C}{\delta \vy_i}=4\sum_{j}{(p_{ij}-q_{ij})(\vy_i-\vy_j)(1+\lVert \vy_i-\vy_j \rVert^2)^{-1}}
\end{equation}

之后用带动量的随机梯度下降算法优化低维空间的数据表示$\mathcal{Y}$即可。


\section{草图特征分析}

为了验证现有图像翻译神经网络对精确度不高、带有几何变形的手绘草图是否能够提取到与作者意图相符的人脸形状特征，我们手绘了198张草图，分辨率为$512\times512$。这些草图可以划分成11类，分别是G1：添加头发；G2：添加新属性，例如胡须、皱纹、耳朵；G3：改变脸型；G4：改变眉毛；G5：改变眼睛形状；G6改变眼睛大小；G7：涂鸦型手绘；G8：改变嘴巴；G9：改变鼻子；G10：改变嘴巴(眼睛与G9相同)；G11：改变鼻子(眼睛与G8相同)。具体的，G7的涂鸦型手绘草图各图之间没有关联。而其余10类中草图都只改变一个特定位置或属性而其他部分保持不变。除G8和G11、G9与G10之间眼睛部位相同以外，其余各类草图的眼睛线条各不相同。图~\ref{fig:hand_drawn_contours}展示了这11组手绘草图示例。
\begin{figure}[htb]
	\centering
	\includegraphics[width=1 \textwidth]{hand_drawn_sketches.png}
	\caption{分类手绘草图示意图}
	\label{fig:hand_drawn_contours}
\end{figure}

如第二章所述，我们选用了目前较为先进的图像翻译神经网络pix2pixHD\cite{pix2pixhd}作为我们从手绘草图到人脸图像的网络模型。

我们以$G_1$指代全局生成器，$G_2$指代局部增强器。由于外层的$G_2$只是单纯为了提高生成图像的分辨率，为了可以更直接地探究问题的本质，我们截取了$G_1$作为模型的生成器。由前文2.2.1可知，$G_1$由3部分组成，分别是：一个卷积前端$G_1^{(F)}$，9个残差模块$G_1^{(R)}$和一个逆卷积后端$G_1^{(B)}$，而$G_1^{(F)}$由5个下采样的卷积层组成。我们分别称$G_1^{(F)}$的前5个卷积层为$L0$...$L4$。由2.3可知，我们的模型在pix2pixHD的$G_1$的基础上去掉了$L0$和$L1$的实例标准化操作，作为我们自己的生成器模型。

把手绘草图输入我们模型的生成器，得到$L0$到$L4$的5张特征图，然后对应输入草图的左眼眼角位置，坐标为(170, 250)，分别在5张特征图上抽取一个点的全通道特征向量，我们称之为$\vv_k,k=0,...\ ,4$。5张特征图上对应点的坐标分别为(170, 250)、(85, 125)、(43, 63)、(22, 32)和(11, 16)，它们在输入草图上的感知野大小分别为7、9、13、21和37。感知野的示意图如图~\ref{fig:receptive}所示：
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.3 \textwidth]{receptive_field.png}
	\caption{$L0\sim L4$特征图的左眼角点在输入草图上的感知野}
	\label{fig:receptive}
\end{figure}

同样地，我们也将手绘草图输入pix2pixHD的$G_1$，按上述方法得到的5个特征向量分别称为$\vv_0^{'}$...$\vv_4^{'}$。这5个特征向量的维数分别为48、96、192、384和768。

将198张输入草图的$\vv_0$和$\vv_1$分别放在一起比较，发现没有改变眼睛的组，比如改变嘴巴的G8和改变鼻子的G9，这两个向量在类内是一致的；而改变了眼睛的组，如改变眼睛形状的G5、改变眼睛大小的G6、涂鸦型手绘G7三组，这两个向量在它们各自的类内是不相等的。把不同草图的$\vv_0^{'}$和$\vv_4^{'}$分别放在一起比较，发现在各自的类内这两个向量都是不相等的。针对发现的这个问题，我们对提取的特征向量进行了可视化的分析。

\section{PCA可视化分析}

主成分分析(PCA)是一种常用的线性降维方法，可以较好地保留数据在高维空间中的特征。接下来我们用PCA对$\vv_0\sim \vv_4$进行降维后的可视化分析。

图~\ref{fig:pca_1}(a)和图~\ref{fig:pca_1}(b)分别是对$\vv_0$和$\vv_1$用PCA降维后可视化的结果，图~\ref{fig:pca_1}(c)是图例(该图例对以下第三章的内容都适用)。从图中可以看出G1、G2、G3、G4类的数据各自分散地分布于同一点，G8和G11类数据分布于同一点，G9和G10类数据分布于同一点，而G5、G6、G7类的数据分布的非常分散。这说明去掉前两层的实例标准化操作之后，左眼角角点位置的特征只受感知野内的草图内容的影响，感知野内草图的改变会使提取到的对应点的特征发生变化，而改变草图其他部分不会对该点的特征产生作用。
\begin{figure}[htb]
	\centering
	\includegraphics[width=1 \textwidth]{pca_1.png}
	\caption{$\vv_0$和$\vv_1$的PCA可视化结果}
	\label{fig:pca_1}
\end{figure}

$\vv_2 \sim \vv_4$的可视化结果分别如图~\ref{fig:pca_2}(a)(b)(c)所示。观察$\vv_2$的PCA可视化结果可以发现，没有改变眼睛的类别，类内的特征分布开始不同，说明实例标准化操作将草图上其他位置的变化传达到了眼睛位置，使眼睛位置的特征发生改变，而不单单只影响改动位置的特征。

对比$\vv_2$和$\vv_3$的PCA可视化结果，可以发现，没有改动眼睛的草图类别，如G1、G2、G3、G4、G8、G9、G10、G11类，类内距离逐渐增大，即同一个类别内特征分布得更为分散。这说明随着逐层增加实例标准化操作，在输入草图上改动其他部位对眼睛位置的特征影响越来越明显，导致最终生成图像的眼睛也发生改变。

对比从$\vv_2$到$\vv_4$的PCA可视化结果，还可以发现，随着卷积层数的加深，G1、G2、G3、G4、G8、G9、G10、G11类特征的类间距离逐渐减小，类间界限逐渐模糊，即不同类别的特征分布得更为集中。这说明随着逐层增加实例标准化操作，由于实例标准化的平均化作用，即使在输入草图上改变眼睛，对特征图上眼睛位置的影响作用也越来越弱。这种现象最终导致生成图像的纹理细节变得模糊，不够清晰。
\begin{figure}[htb]
	\centering
	\includegraphics[width=1 \textwidth]{pca_2.png}
	\caption{$\vv_2 \sim \vv_4$的PCA可视化结果}
	\label{fig:pca_2}
\end{figure}

接下来做的是模型的对比实验，即，把$\vv_0 \sim \vv_4$的可视化结果与$\vv_0^{'} \sim \vv_4^{'}$进行横向对比。

将$\vv_0^{'}$，$\vv_1^{'}$的可视化结果分别与$\vv_0$，$\vv_1$的进行对比，图~\ref{fig:pca_3}(a)(c)分别为$\vv_0$和$\vv_1$的可视化结果，图~\ref{fig:pca_3}(b)(d)分别为$\vv_0^{'}$和$\vv_1^{'}$的可视化结果。因为前两个卷积层有实例标准化的缘故，所以G1、G2、G3、G4、G8、G9、G10、G11类的特征向量$\vv_0^{'}$和$\vv_1^{'}$各自分散地分布，而没有像$\vv_0$与$\vv_1$一样重合于一点。
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8 \textwidth]{pca_3.png}
	\caption{$\vv_0\ ,\vv_1$与$\vv_0^{'}\ ,\vv_1^{'}$的PCA可视化结果对比}
	\label{fig:pca_3}
\end{figure}

分别将$\vv_2^{'} \sim \vv_4^{'}$与$\vv_2 \sim \vv_4$的可视化结果进行横向对比，如图~\ref{fig:pca_4}所示，(a)(b)(c)分别为$\vv_2 \sim \vv4$的PCA可视化结果，(d)(e)(f)分别为$\vv_2^{'} \sim \vv_4^{'}$的可视化结果。我们发现$\vv_2^{'}$，$\vv_3^{'}$，$\vv_4^{'}$中没有改变眼睛的类别，如G1、G2、G3、G4、G8、G9、G10、G11类，其类内距离更大，类别内部分布得更为分散，而$\vv_2$，$\vv_3$和$\vv_4$则有效减少了类内距离，使类内分布得更为集中。这恰恰说明了我们将pix2pixHD的$G_1$的前两个卷积层的实例标准化操作去掉，可以更好地提取到输入草图的低层特征，从而可以有效降低在草图上改变某一部位而对生成图像其他部位产生的影响，同时也丰富了生成图像的纹理细节。
\begin{figure}[htb]
	\centering
	\includegraphics[width=1 \textwidth]{pca_4.png}
	\caption{$\vv_2 \sim \vv4$与$\vv_2^{'} \sim \vv_4^{'}$的PCA可视化结果对比}
	\label{fig:pca_4}
\end{figure}


\section{t-SNE可视化分析}

t-SNE的困惑度参数(perplexity)代表了在求高维空间数据分布时考虑的近邻点的个数，由于我们的草图数据每类的数量平均为15左右，所以取困惑度的值为15。

图~\ref{fig:tsne_1}(a)(b)分别展示了$\vv_0$与$\vv_0^{'}$的t-SNE可视化结果，图~\ref{fig:tsne_1}(c)(d)分别展示了$\vv_1$与$\vv_1^{'}$的t-SNE可视化结果。从图中可以发现，G1、G2、G3、G4、G8、G9、G10、G11类的$\vv_0$、$\vv_1$各自聚类在一起，各类集中地分布，而$\vv_0^{'}$和$\vv_1^{'}$则在类内分布得比较分散。这也说明在$G_1$的$L0$，$L1$去掉实例标准化操作后，在草图上改变其他部位对前两层特征图的眼睛位置没有影响。
\begin{figure}[htb]
	\centering
	\includegraphics[width=1 \textwidth]{tsne_1.png}
	\caption{$\vv_0$，$\vv_1$与$\vv_0^{'}$，$\vv_1^{'}$的t-SNE可视化结果对比}
	\label{fig:tsne_1}
\end{figure}

另外，我们观察$\vv_4$的可视化结果，由图~\ref{fig:tsne_2}可以发现，G8与G11类、G9与G10类的$\vv_4$还是分布在一起，并没有互相分离。这说明，对于比较深层的眼睛部位的特征来说，在草图上修改眼睛依然是最重要的改变，在草图眼睛相同的情况下，无论改变嘴巴还是鼻子都不能对眼睛特征产生足以区分类别的显著影响。输入数据的局部变动对提取到的特征的影响也是局部的，而非全局性的。
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5 \textwidth]{tsne_2.png}
	\caption{$\vv_4$的t-SNE可视化结果}
	\label{fig:tsne_2}
\end{figure}


根据以上观察可以说明，我们的模型能更好的保留草图最底层的特征和最原始的语义信息。



