% !TeX root = ../main.tex

\chapter{总结和展望}

本文研究了目前最成功的图像翻译模型pix2pixHD\cite{pix2pixhd}，并且在我们的CelebA-Contour数据集上训练了该模型。之后用手绘的草图对训练好的模型进行了测试，从测试结果发现pix2pixHD存在以下问题：

1. 生成结果细节不够完美，前额、牙齿等部位经常出现模糊现象；

2. 在草图上改变某一部位常造成生成结果全局性的改变，不能实现图像编辑的功能。

所以，我们通过可视化草图的特征，理论分析了造成以上两点问题的原因，发现根源在于每一层的实例标准化操作。我们遂改进了pix2pixHD的模型，去掉了网络前两层的实例标准化，重新训练模型，并用手绘草图进行测试，发现生成效果明显好于原模型，同时能很好地实现了预期的图像编辑功能。

我们还探索了去掉前面n层(如前5层)实例标准化操作的模型，发现如果去掉的太多，则会造成训练过程很难收敛，最终生成结果反而更差。

在测试过程中我们还发现，如果输入草图偏离参考位置会使生成结果变差。在综合分析原因后我们将数据进行了增广，在训练过程中对输入草图加入了一定程度的平移和旋转。最终的模型对输入草图空间位置变化的鲁棒性大大提高。

但是我们的模型也存在很多问题，比如对于精确度不高、带有几何形变的草图，其生成结果会完全忠实于输入从而使真实感降低，如图~\ref{fig:distorted}~所示。但是这与图像编辑功能是相矛盾的。实现图像编辑意味着模型需要对输入“敏感”，草图上的细微改变也能影响生成的结果；而对精度很差的输入也要生成真实感强的照片则需要模型降低对输入的依赖，变得“迟钝”，才能具有纠偏的能力。
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.65 \textwidth]{distorted.png}
	\caption{带有变形输入的生成结果对比}
	\label{fig:distorted}
\end{figure}

所以我们未来要设计一种新的空间自适应的标准化方法，使得以上两点要求能同时满足。对于眼睛、眉毛、鼻子等力求结构精细的部位，我们希望生成结果尽可能贴近输入草图的形状；而对于脸型属性，由于其本身形状比较规则且左右对称，而人们手绘的草图脸型往往很难画好，所以我们希望模型能减少对脸型轮廓信息的依赖程度，增强生成照片的真实感。

我们的模型对头发的生成做的也不是很好，这是由于训练集轮廓图缺少头发信息造成的。其他类型的草图，比如边缘图或掩膜边界图等，都包含有头发信息，但是它们都比较复杂，缺少绘画基础的普通人很难画出类似的手绘草图。所以我们期望找到一种更好地草图生成方法，在轮廓图的基础上加入头发的样式信息，同时保证可以手绘出风格相近的草图。

希望经过最终的努力，能逐步解决上述问题，不断完善现有的模型，同时完善理论层面的论证，使得模型的生成质量越来越高，鲁棒性越来越强，图像编辑功能越来越强大。

